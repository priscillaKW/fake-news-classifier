{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engeneering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este notebook contém a etapa de feature engineering dos conjuntos de treino e teste. Essa etapa se baseia no pré-processamento da etapa de Exploratory Analisys, realizada anteriormente.\n",
    "\n",
    "Ao final dessa etapa, serão gerados dois conjuntos de dados de treino e teste processados, que serão utilizados para treinamento e teste dos modelos de classificação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importação de bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import * \n",
    "from nltk import word_tokenize as TK\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "import nltk\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer, LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importação dos datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read datasets\n",
    "train = pd.read_csv('dataset/train.csv', encoding='utf-8')\n",
    "test = pd.read_csv('dataset/test.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existem 20800 exemplo, no dataset de treinamento. Cada exemplo contém 5 atributos, sendo: id, title, author, text, label.\n"
     ]
    }
   ],
   "source": [
    "print(\"Existem {} exemplo, no dataset de treinamento. Cada exemplo contém {} atributos, sendo: \"\n",
    "      .format(train.shape[0],train.shape[1]) + \", \".join(train.columns) + '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>Darrell Lucus</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Daniel J. Flynn</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>Consortiumnews.com</td>\n",
       "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>Jessica Purkiss</td>\n",
       "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>Howard Portnoy</td>\n",
       "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title              author  \\\n",
       "0   0  House Dem Aide: We Didn’t Even See Comey’s Let...       Darrell Lucus   \n",
       "1   1  FLYNN: Hillary Clinton, Big Woman on Campus - ...     Daniel J. Flynn   \n",
       "2   2                  Why the Truth Might Get You Fired  Consortiumnews.com   \n",
       "3   3  15 Civilians Killed In Single US Airstrike Hav...     Jessica Purkiss   \n",
       "4   4  Iranian woman jailed for fictional unpublished...      Howard Portnoy   \n",
       "\n",
       "                                                text  label  \n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...      1  \n",
       "1  Ever get the feeling your life circles the rou...      0  \n",
       "2  Why the Truth Might Get You Fired October 29, ...      1  \n",
       "3  Videos 15 Civilians Killed In Single US Airstr...      1  \n",
       "4  Print \\nAn Iranian woman has been sentenced to...      1  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualização das 5 primeiras notícias do conjunto de treino\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existem 5200 exemplo, no dataset de treinamento. Cada exemplo contém 4 atributos, sendo: id, title, author, text, label.\n"
     ]
    }
   ],
   "source": [
    "print(\"Existem {} exemplo, no dataset de treinamento. Cada exemplo contém {} atributos, sendo: \"\n",
    "      .format(test.shape[0],test.shape[1]) + \", \".join(train.columns) + '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20800</td>\n",
       "      <td>Specter of Trump Loosens Tongues, if Not Purse...</td>\n",
       "      <td>David Streitfeld</td>\n",
       "      <td>PALO ALTO, Calif.  —   After years of scorning...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20801</td>\n",
       "      <td>Russian warships ready to strike terrorists ne...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Russian warships ready to strike terrorists ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20802</td>\n",
       "      <td>#NoDAPL: Native American Leaders Vow to Stay A...</td>\n",
       "      <td>Common Dreams</td>\n",
       "      <td>Videos #NoDAPL: Native American Leaders Vow to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20803</td>\n",
       "      <td>Tim Tebow Will Attempt Another Comeback, This ...</td>\n",
       "      <td>Daniel Victor</td>\n",
       "      <td>If at first you don’t succeed, try a different...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20804</td>\n",
       "      <td>Keiser Report: Meme Wars (E995)</td>\n",
       "      <td>Truth Broadcast Network</td>\n",
       "      <td>42 mins ago 1 Views 0 Comments 0 Likes 'For th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              title  \\\n",
       "0  20800  Specter of Trump Loosens Tongues, if Not Purse...   \n",
       "1  20801  Russian warships ready to strike terrorists ne...   \n",
       "2  20802  #NoDAPL: Native American Leaders Vow to Stay A...   \n",
       "3  20803  Tim Tebow Will Attempt Another Comeback, This ...   \n",
       "4  20804                    Keiser Report: Meme Wars (E995)   \n",
       "\n",
       "                    author                                               text  \n",
       "0         David Streitfeld  PALO ALTO, Calif.  —   After years of scorning...  \n",
       "1                      NaN  Russian warships ready to strike terrorists ne...  \n",
       "2            Common Dreams  Videos #NoDAPL: Native American Leaders Vow to...  \n",
       "3            Daniel Victor  If at first you don’t succeed, try a different...  \n",
       "4  Truth Broadcast Network  42 mins ago 1 Views 0 Comments 0 Likes 'For th...  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualização das 5 primeiras notícias do conjunto de teste\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamento dos dados\n",
    "Nessa etapa serão realizados alguns tratamentos nos dados de treinamento e teste:\n",
    "* Tratamento de missing values\n",
    "* Conversão de todas as palavras para letras minúsculas\n",
    "* Remoção de caracteres númericos e especiais\n",
    "* Remoção de stopwords\n",
    "* Lematização das palavras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tratamento de missing values e outros exemplos que precisam ser removidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remover exemplos com string nula\n",
    "train = train[~train['text'].isnull()]\n",
    "test = test[~test['text'].isnull()]\n",
    "\n",
    "# preenche títulos nulos com string vazia\n",
    "train['title'].fillna('',inplace=True)\n",
    "test['title'].fillna('',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata as ud\n",
    "\n",
    "latin_letters= {}\n",
    "\n",
    "def is_latin(uchr):\n",
    "    try: return latin_letters[uchr]\n",
    "    except KeyError:\n",
    "         return latin_letters.setdefault(uchr, 'LATIN' in ud.name(uchr))\n",
    "\n",
    "def only_roman_chars(unistr):\n",
    "    return all(is_latin(uchr)\n",
    "           for uchr in unistr\n",
    "           if uchr.isalpha()) # isalpha suggested by John Machin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20478, 6)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remover exemplos com texto em outros alfabetos\n",
    "train['only_roman_chars'] = train['text'].apply(only_roman_chars)\n",
    "train = train[train['only_roman_chars']==True]\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5112, 5)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['only_roman_chars'] = train['text'].apply(only_roman_chars)\n",
    "test = test[test['only_roman_chars']==True]\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Concatenação do título com o texto\n",
    "\n",
    "Para que o título seja considerado nas análises, as strings serão concatenadas e serão analisadas em conjunto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['title_text'] = train['title'] + ' ' + train['text']\n",
    "test['title_text'] = test['title'] + ' ' + test['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Conversão para minúsculas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['processed_text'] = train['title_text'].str.lower()\n",
    "test['processed_text'] = test['title_text'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tokenização de texto e título"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['processed_text'] = train['processed_text'].apply(lambda x:list(nltk.word_tokenize(x)))\n",
    "test['processed_text'] = test['processed_text'].apply(lambda x:list(nltk.word_tokenize(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Remoção de números, caracteres especiais\n",
    "É necessário realizar uma limpeza no texto para igualar palavras iguais que podem ter sido escritas de forma incorreta ou diferente, palavras que não tem sentido sozinhos como números. Para isso faremos:\n",
    "- remoção de caracteres numéricos\n",
    "- remoção de caracteres especiais e pontuação\n",
    "- remoção de acentos, hífens, apóstrofo\n",
    "- remoção de stopwords\n",
    "- stemming\n",
    "- lematização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retira os caracteres numéricos \n",
    "train['processed_text'] = train['processed_text'].apply(lambda x: [re.sub('[0-9]', '',i) for i in x])\n",
    "test['processed_text'] = test['processed_text'].apply(lambda x: [re.sub('[0-9]', '',i) for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retira os caracteres especiais e pontuação\n",
    "train['processed_text'] = train['processed_text'].apply(lambda x: [re.sub('[?_!%&/.,®€™():]', '',i) for i in x])\n",
    "train['processed_text'] = train['processed_text'].apply(lambda x: [i.replace(\"\\\\r\", \"\").replace(\"\\\\n\",\"\") for i in x])\n",
    "\n",
    "test['processed_text'] = test['processed_text'].apply(lambda x: [re.sub('[?_!%&/.,®€™():]', '',i) for i in x])\n",
    "test['processed_text'] = test['processed_text'].apply(lambda x: [i.replace(\"\\\\r\", \"\").replace(\"\\\\n\",\"\") for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove hífen e apóstrofo, adicionando espaço no lugar\n",
    "train['processed_text'] = train['processed_text'].apply(lambda x: [re.sub('[-“”[—‘’\\']', ' ',i) for i in x])\n",
    "test['processed_text'] = test['processed_text'].apply(lambda x: [re.sub('[-“”[—‘’\\']', ' ',i) for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remoção de acentos\n",
    "train['processed_text'] = train['processed_text'].apply(lambda x: [i.replace('â', \"a\").replace('è', 'e').replace('é', 'e').replace('í', 'i').replace('î', 'i').replace('ú', 'u').replace('ç', 'c') for i in x])\n",
    "test['processed_text'] = test['processed_text'].apply(lambda x: [i.replace('â', \"a\").replace('è', 'e').replace('é', 'e').replace('í', 'i').replace('î', 'i').replace('ú', 'u').replace('ç', 'c') for i in x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Remoção de stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lista de stopwords em inglês\n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "train['processed_text'] = train['processed_text'].apply(lambda x: [item for item in x if item not in stop_words])\n",
    "test['processed_text'] = test['processed_text'].apply(lambda x: [item for item in x if item not in stop_words])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lematização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "train['processed_text'] = train['processed_text'].apply(lambda x:  [lemmatizer.lemmatize(w) for w in x])\n",
    "test['processed_text'] = test['processed_text'].apply(lambda x:  [lemmatizer.lemmatize(w) for w in x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()  \n",
    "train['processed_text'] = train['processed_text'].apply(lambda x:  [stemmer.stem(i) for i in x])\n",
    "test['processed_text'] = test['processed_text'].apply(lambda x:  [stemmer.stem(i) for i in x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Remoção de palavras vazias (espaços em branco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['processed_text'] = train['processed_text'].apply(lambda x: [a.strip() for a in x if a.strip()])\n",
    "test['processed_text'] = test['processed_text'].apply(lambda x: [a.strip() for a in x if a.strip()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exclusão das notícias repetidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cria variável de texto, com palavras separadas por vírgula\n",
    "train[\"words_text\"] = train[\"processed_text\"].apply(lambda x: \", \".join(x))\n",
    "test[\"words_text\"] = test[\"processed_text\"].apply(lambda x: \", \".join(x))\n",
    "\n",
    "# removendo casos duplicados\n",
    "train.drop_duplicates(subset=['words_text'], keep='first', inplace=True)\n",
    "test.drop_duplicates(subset=['words_text'], keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criação de novas features\n",
    "\n",
    "Uma feature foi criada na etapa anterior e contém: a lista de palavras de cada notícia concatenadas em apenas uma string, separadas por vírgula.\n",
    "Com base na coluna de texto e título processado, será criada, para cada coluna, uma nova feature com a quantidade de palavras de cada texto e cada título"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['processed_word_count'] = train['processed_text'].apply(lambda x: len(x))\n",
    "test['processed_word_count'] = test['processed_text'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removendo textos que ficaram vazios após o tratamento e limpeza\n",
    "train = train[train['processed_word_count']!=0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets após o tratamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O conjunto de treinamento processado possui 20339 exemplos e 10 colunas:\n"
     ]
    }
   ],
   "source": [
    "print(\"O conjunto de treinamento processado possui {} exemplos e \\\n",
    "{} colunas:\".format(train.shape[0],train.shape[1])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>only_roman_chars</th>\n",
       "      <th>title_text</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>words_text</th>\n",
       "      <th>processed_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>Darrell Lucus</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>[hous, dem, aid, even, see, comey, letter, jas...</td>\n",
       "      <td>hous, dem, aid, even, see, comey, letter, jaso...</td>\n",
       "      <td>445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Daniel J. Flynn</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>[flynn, hillari, clinton, big, woman, campu, b...</td>\n",
       "      <td>flynn, hillari, clinton, big, woman, campu, br...</td>\n",
       "      <td>374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>Consortiumnews.com</td>\n",
       "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>Why the Truth Might Get You Fired Why the Trut...</td>\n",
       "      <td>[truth, might, get, fire, truth, might, get, f...</td>\n",
       "      <td>truth, might, get, fire, truth, might, get, fi...</td>\n",
       "      <td>697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>Jessica Purkiss</td>\n",
       "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>[civilian, kill, singl, u, airstrik, identifi,...</td>\n",
       "      <td>civilian, kill, singl, u, airstrik, identifi, ...</td>\n",
       "      <td>309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>Howard Portnoy</td>\n",
       "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>[iranian, woman, jail, fiction, unpublish, sto...</td>\n",
       "      <td>iranian, woman, jail, fiction, unpublish, stor...</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title              author  \\\n",
       "0   0  House Dem Aide: We Didn’t Even See Comey’s Let...       Darrell Lucus   \n",
       "1   1  FLYNN: Hillary Clinton, Big Woman on Campus - ...     Daniel J. Flynn   \n",
       "2   2                  Why the Truth Might Get You Fired  Consortiumnews.com   \n",
       "3   3  15 Civilians Killed In Single US Airstrike Hav...     Jessica Purkiss   \n",
       "4   4  Iranian woman jailed for fictional unpublished...      Howard Portnoy   \n",
       "\n",
       "                                                text  label  only_roman_chars  \\\n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...      1              True   \n",
       "1  Ever get the feeling your life circles the rou...      0              True   \n",
       "2  Why the Truth Might Get You Fired October 29, ...      1              True   \n",
       "3  Videos 15 Civilians Killed In Single US Airstr...      1              True   \n",
       "4  Print \\nAn Iranian woman has been sentenced to...      1              True   \n",
       "\n",
       "                                          title_text  \\\n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...   \n",
       "1  FLYNN: Hillary Clinton, Big Woman on Campus - ...   \n",
       "2  Why the Truth Might Get You Fired Why the Trut...   \n",
       "3  15 Civilians Killed In Single US Airstrike Hav...   \n",
       "4  Iranian woman jailed for fictional unpublished...   \n",
       "\n",
       "                                      processed_text  \\\n",
       "0  [hous, dem, aid, even, see, comey, letter, jas...   \n",
       "1  [flynn, hillari, clinton, big, woman, campu, b...   \n",
       "2  [truth, might, get, fire, truth, might, get, f...   \n",
       "3  [civilian, kill, singl, u, airstrik, identifi,...   \n",
       "4  [iranian, woman, jail, fiction, unpublish, sto...   \n",
       "\n",
       "                                          words_text  processed_word_count  \n",
       "0  hous, dem, aid, even, see, comey, letter, jaso...                   445  \n",
       "1  flynn, hillari, clinton, big, woman, campu, br...                   374  \n",
       "2  truth, might, get, fire, truth, might, get, fi...                   697  \n",
       "3  civilian, kill, singl, u, airstrik, identifi, ...                   309  \n",
       "4  iranian, woman, jail, fiction, unpublish, stor...                    99  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualização das cinco primeira notícias presentes no conjunto de treino\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O conjunto de teste processado possui 5106 exemplos e 9 colunas:\n"
     ]
    }
   ],
   "source": [
    "print(\"O conjunto de teste processado possui {} exemplos e \\\n",
    "{} colunas:\".format(test.shape[0],test.shape[1])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>only_roman_chars</th>\n",
       "      <th>title_text</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>words_text</th>\n",
       "      <th>processed_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20800</td>\n",
       "      <td>Specter of Trump Loosens Tongues, if Not Purse...</td>\n",
       "      <td>David Streitfeld</td>\n",
       "      <td>PALO ALTO, Calif.  —   After years of scorning...</td>\n",
       "      <td>True</td>\n",
       "      <td>Specter of Trump Loosens Tongues, if Not Purse...</td>\n",
       "      <td>[specter, trump, loosen, tongu, purs, string, ...</td>\n",
       "      <td>specter, trump, loosen, tongu, purs, string, s...</td>\n",
       "      <td>776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20801</td>\n",
       "      <td>Russian warships ready to strike terrorists ne...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Russian warships ready to strike terrorists ne...</td>\n",
       "      <td>True</td>\n",
       "      <td>Russian warships ready to strike terrorists ne...</td>\n",
       "      <td>[russian, warship, readi, strike, terrorist, n...</td>\n",
       "      <td>russian, warship, readi, strike, terrorist, ne...</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20802</td>\n",
       "      <td>#NoDAPL: Native American Leaders Vow to Stay A...</td>\n",
       "      <td>Common Dreams</td>\n",
       "      <td>Videos #NoDAPL: Native American Leaders Vow to...</td>\n",
       "      <td>True</td>\n",
       "      <td>#NoDAPL: Native American Leaders Vow to Stay A...</td>\n",
       "      <td>[#, nodapl, nativ, american, leader, vow, stay...</td>\n",
       "      <td>#, nodapl, nativ, american, leader, vow, stay,...</td>\n",
       "      <td>447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20803</td>\n",
       "      <td>Tim Tebow Will Attempt Another Comeback, This ...</td>\n",
       "      <td>Daniel Victor</td>\n",
       "      <td>If at first you don’t succeed, try a different...</td>\n",
       "      <td>True</td>\n",
       "      <td>Tim Tebow Will Attempt Another Comeback, This ...</td>\n",
       "      <td>[tim, tebow, attempt, anoth, comeback, time, b...</td>\n",
       "      <td>tim, tebow, attempt, anoth, comeback, time, ba...</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20804</td>\n",
       "      <td>Keiser Report: Meme Wars (E995)</td>\n",
       "      <td>Truth Broadcast Network</td>\n",
       "      <td>42 mins ago 1 Views 0 Comments 0 Likes 'For th...</td>\n",
       "      <td>True</td>\n",
       "      <td>Keiser Report: Meme Wars (E995) 42 mins ago 1 ...</td>\n",
       "      <td>[keiser, report, meme, war, e, min, ago, view,...</td>\n",
       "      <td>keiser, report, meme, war, e, min, ago, view, ...</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              title  \\\n",
       "0  20800  Specter of Trump Loosens Tongues, if Not Purse...   \n",
       "1  20801  Russian warships ready to strike terrorists ne...   \n",
       "2  20802  #NoDAPL: Native American Leaders Vow to Stay A...   \n",
       "3  20803  Tim Tebow Will Attempt Another Comeback, This ...   \n",
       "4  20804                    Keiser Report: Meme Wars (E995)   \n",
       "\n",
       "                    author                                               text  \\\n",
       "0         David Streitfeld  PALO ALTO, Calif.  —   After years of scorning...   \n",
       "1                      NaN  Russian warships ready to strike terrorists ne...   \n",
       "2            Common Dreams  Videos #NoDAPL: Native American Leaders Vow to...   \n",
       "3            Daniel Victor  If at first you don’t succeed, try a different...   \n",
       "4  Truth Broadcast Network  42 mins ago 1 Views 0 Comments 0 Likes 'For th...   \n",
       "\n",
       "  only_roman_chars                                         title_text  \\\n",
       "0             True  Specter of Trump Loosens Tongues, if Not Purse...   \n",
       "1             True  Russian warships ready to strike terrorists ne...   \n",
       "2             True  #NoDAPL: Native American Leaders Vow to Stay A...   \n",
       "3             True  Tim Tebow Will Attempt Another Comeback, This ...   \n",
       "4             True  Keiser Report: Meme Wars (E995) 42 mins ago 1 ...   \n",
       "\n",
       "                                      processed_text  \\\n",
       "0  [specter, trump, loosen, tongu, purs, string, ...   \n",
       "1  [russian, warship, readi, strike, terrorist, n...   \n",
       "2  [#, nodapl, nativ, american, leader, vow, stay...   \n",
       "3  [tim, tebow, attempt, anoth, comeback, time, b...   \n",
       "4  [keiser, report, meme, war, e, min, ago, view,...   \n",
       "\n",
       "                                          words_text  processed_word_count  \n",
       "0  specter, trump, loosen, tongu, purs, string, s...                   776  \n",
       "1  russian, warship, readi, strike, terrorist, ne...                   159  \n",
       "2  #, nodapl, nativ, american, leader, vow, stay,...                   447  \n",
       "3  tim, tebow, attempt, anoth, comeback, time, ba...                   365  \n",
       "4  keiser, report, meme, war, e, min, ago, view, ...                    57  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualização das cinco primeira notícias presentes no conjunto de treino\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF e exportação dos datasets processados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Salvar os valores de target e ids em um novo arquivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.reset_index(drop=True)\n",
    "y_train = train['label']\n",
    "pd.DataFrame(y_train, columns=['target']).to_csv(\"dataset/train_target.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_train = list(train.index)\n",
    "ids_train = train['id']\n",
    "d = {'index': index_train, 'id': ids_train}\n",
    "pd.DataFrame(d).to_csv(\"dataset/train_ids.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF\n",
    "\n",
    "Como os modelos preditivos não trabalham diretamente com textos, é necessário realizar a vetorização da lista de palavras das notícias. Será utilizado o método TF-IDF para isso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf(df):\n",
    "    df = df.reset_index(drop=True)\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf = vectorizer.fit_transform(df['words_text'])\n",
    "    #print(vectorizer.get_feature_names())\n",
    "    print(tfidf.shape)\n",
    "    return tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20339, 115846)\n"
     ]
    }
   ],
   "source": [
    "df=train\n",
    "tfidf_train = tf_idf(df)\n",
    "X_train = tfidf_train\n",
    "scipy.sparse.save_npz('dataset/processed_train.npz', X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5106, 66718)\n"
     ]
    }
   ],
   "source": [
    "tfidf_test = tf_idf(test)\n",
    "X_test = tfidf_test\n",
    "scipy.sparse.save_npz('dataset/processed_test.npz', X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
